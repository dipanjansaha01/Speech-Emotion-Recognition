# ğŸ¤ Speech Emotion Recognition using LSTM

## ğŸ“Œ Overview
Speech Emotion Recognition (SER) is a system that identifies human emotions from voice signals. This project leverages **Long Short-Term Memory (LSTM)** networks to analyze speech patterns and classify emotions based on extracted features.

---

## âœ¨ Features
âœ… Preprocessing of audio signals  
âœ… Feature extraction (MFCCs, Chroma, Mel Spectrograms)  
âœ… LSTM-based deep learning model for emotion classification  
âœ… Model evaluation and performance metrics  

---

## ğŸ“‚ Dataset
ğŸ“¥ **Download Link:** [Toronto Emotional Speech Set (TESS)](https://www.kaggle.com/ejlok1/toronto-emotional-speech-set-tess)

### ğŸ“œ Dataset Information
- **Speakers:** 2 Female Actresses (aged 26 and 64)
- **Total Audio Files:** 2800 WAV files
- **Emotions Covered:**
  - ğŸ˜  Anger  
  - ğŸ¤¢ Disgust  
  - ğŸ˜¨ Fear  
  - ğŸ˜ƒ Happiness  
  - ğŸ˜² Pleasant Surprise  
  - ğŸ˜¢ Sadness  
  - ğŸ˜ Neutral  

---

## ğŸ” Steps Involved
1ï¸âƒ£ **Data Preprocessing:** Load and preprocess audio files.  
2ï¸âƒ£ **Feature Extraction:** Extract **Mel-Frequency Cepstral Coefficients (MFCCs)** and other relevant features.  
3ï¸âƒ£ **Model Training:** Train an **LSTM model** on the extracted features.  
4ï¸âƒ£ **Evaluation:** Test the model and analyze **accuracy, precision, recall, and confusion matrix**.  

---

## ğŸ“Š Results
ğŸ¯ The trained model achieves an **accuracy of 97%** in classifying emotions from speech. Detailed evaluation metrics are available in the notebook.
